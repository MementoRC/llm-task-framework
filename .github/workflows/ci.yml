name: CI

on:
  push:
    branches: [ main, master, development ]
  pull_request:
    branches: [ main, master, development ]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHONPATH: src
  PYTHONUNBUFFERED: "1"
  FORCE_COLOR: "1"

jobs:
  quality-checks:
    name: Quality Checks
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Set up Pixi
      uses: prefix-dev/setup-pixi@v0.8.8
      with:
        pixi-version: v0.34.0
        cache: true
    
    - name: Check code formatting
      run: pixi run format-check
    
    - name: Run linting
      run: pixi run lint
    
    - name: Run type checking
      run: pixi run typecheck
    
    - name: Run security scans
      run: pixi run -e security security-all
    
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  test:
    name: Test Python ${{ matrix.python-version }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.10", "3.11", "3.12"]
        exclude:
          # Skip some combinations for faster CI
          - os: windows-latest
            python-version: "3.10"
          - os: macos-latest
            python-version: "3.10"
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Pixi
      uses: prefix-dev/setup-pixi@v0.8.8
      with:
        pixi-version: v0.34.0
        cache: true
    
    - name: Run tests with coverage
      run: pixi run test-cov
      env:
        # Disable LLM tests in CI unless API keys provided
        SKIP_LLM_TESTS: ${{ !secrets.ANTHROPIC_API_KEY && !secrets.OPENAI_API_KEY }}
    
    - name: Upload coverage to Codecov
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      uses: codecov/codecov-action@v3
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [quality-checks]
    if: github.event_name != 'pull_request' || github.event.pull_request.draft == false
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Pixi
      uses: prefix-dev/setup-pixi@v0.8.8
      with:
        pixi-version: v0.34.0
        cache: true
    
    - name: Run integration tests
      run: pixi run test-integration
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
    
    - name: Run MCP server tests
      run: pixi run test-mcp

  build-and-test-package:
    name: Build and Test Package
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [test]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Pixi
      uses: prefix-dev/setup-pixi@v0.8.8
      with:
        pixi-version: v0.34.0
        cache: true
    
    - name: Build package
      run: pixi run build
    
    - name: Check package
      run: pixi run -e dev sh -c "pip install twine && twine check dist/*"
    
    - name: Test package installation
      run: |
        pixi run -e prod sh -c "pip install dist/*.whl"
        pixi run -e prod python -c "import llm_task_framework; print('Package imported successfully')"
        pixi run -e prod llm-task-framework --help
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dist-packages
        path: dist/
        retention-days: 30

  # Performance baseline (non-blocking)
  performance:
    name: Performance Baseline
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [test]
    continue-on-error: true
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Pixi
      uses: prefix-dev/setup-pixi@v0.8.8
      with:
        pixi-version: v0.34.0
        cache: true
    
    - name: Install benchmark dependencies
      run: pixi run -e dev pip install pytest-benchmark
    
    - name: Run performance tests
      run: pixi run -e dev pytest -m "not slow" --benchmark-only --benchmark-json=benchmark.json
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results
        path: benchmark.json
        retention-days: 30

  # Documentation build check
  docs:
    name: Documentation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Pixi
      uses: prefix-dev/setup-pixi@v0.8.8
      with:
        pixi-version: v0.34.0
        cache: true
    
    - name: Build documentation
      run: pixi run -e docs docs-build
    
    - name: Upload documentation
      uses: actions/upload-artifact@v4
      with:
        name: documentation
        path: site/
        retention-days: 30

  # Final status check
  ci-success:
    name: CI Success
    runs-on: ubuntu-latest
    needs: [quality-checks, test, integration-tests, build-and-test-package, docs]
    if: always()
    
    steps:
    - name: Check CI status
      run: |
        if [[ "${{ needs.quality-checks.result }}" != "success" ]]; then
          echo "Quality checks failed"
          exit 1
        fi
        if [[ "${{ needs.test.result }}" != "success" ]]; then
          echo "Tests failed"
          exit 1
        fi
        if [[ "${{ needs.integration-tests.result }}" != "success" && "${{ needs.integration-tests.result }}" != "skipped" ]]; then
          echo "Integration tests failed"
          exit 1
        fi
        if [[ "${{ needs.build-and-test-package.result }}" != "success" ]]; then
          echo "Package build failed"
          exit 1
        fi
        if [[ "${{ needs.docs.result }}" != "success" ]]; then
          echo "Documentation build failed"
          exit 1
        fi
        echo "All CI checks passed!"